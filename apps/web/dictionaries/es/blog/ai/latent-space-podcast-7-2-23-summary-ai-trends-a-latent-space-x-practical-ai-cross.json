{
  "relatedBlogs": [
    {
      "id": "190259319",
      "topics": ["Resumen", "LLM", "Entrenamiento"],
      "title": "Podcast Latent Space 16/8/23 [Resumen] - Las matematicas del entrenamiento de LLMs — con Quentin Anthony de Eleuther AI",
      "slug": "latent-space-podcast-8-16-23-summary-the-mathematics-of-training-llms-with-que",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:19:45+01:00",
      "description": "Explora las matematicas detras del entrenamiento de LLMs con Quentin Anthony de Eleuther AI. Profundiza en el articulo Transformers Math 101 y domina tecnicas de entrenamiento distribuido para maximo rendimiento de GPU.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 16/8/23 [Resumen] Matematicas del entrenamiento de LLMs",
        "description": "Profundiza en el articulo Transformers Math 101 y domina tecnicas de entrenamiento distribuido para maximo rendimiento de GPU."
      }
    },
    {
      "id": "190259129",
      "topics": ["LLM", "Hardware", "Resumen", "Edge"],
      "title": "Podcast Latent Space 10/8/23 [Resumen]: LLMs en todas partes: Ejecutando modelos de 70B en navegadores e iPhones usando MLC — con Tianqi Chen de CMU / OctoML",
      "slug": "latent-space-podcast-8-10-23-summary-llms-everywhere-running-70b-models-in-browse",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:18:37+01:00",
      "description": "Explora la magia de MLC con Tianqi Chen: implementando modelos de 70B en navegadores e iPhones. Profundiza en XGBoost, la creacion de TVM y el futuro de las implementaciones de IA universales.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
      },
      "seo": {
        "title": "Latent Space 10/8/23 [Resumen]: LLMs en todas partes",
        "description": "Explora la implementacion de modelos de 70B en navegadores e iPhones. Profundiza en XGBoost, la creacion de TVM y el futuro de las implementaciones de IA universales."
      }
    },
    {
      "id": "190259087",
      "topics": ["Resumen", "LLM", "Codigo", "Codigo Abierto", "Modelos Pequenos"],
      "title": "Podcast Latent Space 4/8/23 [Resumen] Episodio cruzado de Latent Space x AI Breakdown!",
      "slug": "latent-space-podcast-8-4-23-summary-latent-space-x-ai-breakdown-crossover-pod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:16:33+01:00",
      "description": "Unete a AI Breakdown y Latent Space para el resumen tecnologico de IA del verano: Profundiza en GPT4.5, Llama 2, herramientas de IA, el creciente ingeniero de IA y mas!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 4/8/23 [Resumen] Episodio cruzado con AI Breakdown",
        "description": "Profundiza en GPT4.5, Llama 2, herramientas de IA, el creciente ingeniero de IA y mas!"
      }
    },
    {
      "id": "190259111",
      "topics": ["Resumen", "Transformers", "Entrenamiento", "Codigo Abierto"],
      "title": "Podcast Latent Space 26/7/23 [Resumen] FlashAttention 2: haciendo Transformers 800% mas rapidos - Tri Dao de Together AI",
      "slug": "latent-space-podcast-7-26-23-summary-flashattention-2-making-transformers-800-fas",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:14:13+01:00",
      "description": "Descubre como FlashAttention revoluciono la velocidad de la IA con Tri Dao, mientras revela el poder de FlashAttention 2, profundiza en el Laboratorio Hazy de Stanford y perspectivas futuras de IA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 26/7/23 [Resumen] FlashAttention 2",
        "description": "Descubre como FlashAttention revoluciono la velocidad de la IA con Tri Dao, mientras revela el poder de FlashAttention 2"
      }
    },
    {
      "id": "190259172",
      "topics": ["Resumen", "LLM", "Codigo Abierto", "Modelos Pequenos"],
      "title": "Podcast Latent Space 19/7/23 [Resumen] - Llama 2: El nuevo SOTA de LLM abierto (con Nathan Lambert, Matt Bornstein, Anton Troynikov, Russell Kaplan, Whole Mars Catalog y otros)",
      "slug": "latent-space-podcast-7-19-23-summary-llama-2-the-new-open-llm-sota-ft-nathan-lamb",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:12:38+01:00",
      "description": "Explora Llama 2, el ultimo avance en IA con expertos Nathan Lambert, Matt Bornstein y mas. Profundiza en conjuntos de datos, benchmarks y predicciones de IA. Te esperan perspectivas y drama de Llama en este podcast destacado!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 19/7/23 [Resumen] - Llama 2",
        "description": "Profundiza en conjuntos de datos, benchmarks y predicciones de IA. Te esperan perspectivas y drama de Llama en este podcast destacado!"
      }
    },
    {
      "id": "190259191",
      "topics": ["Resumen", "Codigo", "LLM"],
      "title": "Podcast Latent Space 10/7/23 [Resumen] - Interprete de Codigo == GPT 4.5 (con Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley y otros)",
      "slug": "latent-space-podcast-7-10-23-summary-code-interpreter-gpt-4-5-w-simon-willison-al",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:09:26+01:00",
      "description": "Explora el Interprete de Codigo de ChatGPT: un cambio de juego en IA. Profundiza en su salto de capacidades de 1000x con Simon, Alex y expertos en IA. #InferenciaAumentadaPorCodigo #GPT4_5",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space [Resumen] Interprete de Codigo = GPT 4.5",
        "description": "Explora el Interprete de Codigo de ChatGPT: un cambio de juego en IA. Profundiza en su salto de capacidades de 1000x con Simon, Alex y expertos en IA."
      }
    },
    {
      "id": "190259238",
      "topics": ["Hardware", "LLM", "Resumen"],
      "title": "Podcast Latent Space 20/6/23 [Resumen] - Mercantilizando el Petaflop — con George Hotz de tiny corp",
      "slug": "latent-space-podcast-6-20-23-summary-commoditizing-the-petaflop-with-george-ho",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:07:15+01:00",
      "description": "George Hotz de tiny corp desafia a Nvidia y Google! Sumérgete en el mundo de las colaboraciones con AMD, perspectivas sobre ggml, Mojo, Elon y GPT-4, ademas de un vistazo a AI Girlfriend.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 20/6/23 [Resumen] - George Hotz",
        "description": "George Hotz de tiny corp desafia a Nvidia y Google! Colaboraciones con AMD, perspectivas sobre ggml, Mojo, Elon y GPT-4, ademas de un vistazo a AI Girlfriend."
      }
    },
    {
      "id": "190259294",
      "topics": ["LLM", "Funciones", "Resumen"],
      "title": "Podcast Latent Space 14/6/23 [Resumen] - Episodio de Emergencia: nueva API de Funciones de OpenAI, 75% de reduccion de precios, 4x longitud de contexto (con Alex Volkov, Simon Willison, Riley Goodside, Joshua Lochner, Stefania Druga, Eric Elliott, Mayo Oshin y otros)",
      "slug": "latent-space-podcast-6-14-23-summary-emergency-pod-openai-s-new-functions-api-75",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:05:04+01:00",
      "description": "Explora las actualizaciones de OpenAI de junio 2023 con ingenieros de IA de Scale, Microsoft, Pinecone y Huggingface. Profundiza en los paradigmas de Codigo x LLM y descubre los Agentes de Funciones Recursivas.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 20/6/23 [Resumen] - Episodio de Emergencia",
        "description": "Explora las actualizaciones de OpenAI de junio 2023 con ingenieros de IA de Scale, Microsoft, Pinecone y Huggingface."
      }
    },
    {
      "id": "190259333",
      "topics": ["LLM", "Resumen", "UX"],
      "title": "Podcast Latent Space 8/6/23 [Resumen] - De RLHF a RLHB: El caso del aprendizaje del comportamiento humano - con Jeffrey Wang y Joe Reeve de Amplitude",
      "slug": "latent-space-podcast-6-8-23-summary-from-rlhf-to-rlhb-the-case-for-learning-from",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:02:33+01:00",
      "description": "Explora IA y analitica con Jeffrey Wang y Joe Reeve en Latent Space Live! Profundiza en por que la IA valora la Analitica y el poder de los datos de comportamiento de primera mano.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 8/6/23 [Resumen] - De RLHF a RLHB",
        "description": "Explora IA y analitica con Jeffrey Wang y Joe Reeve en Latent Space Live! Profundiza en por que la IA valora la Analitica y el poder de los datos de comportamiento de primera mano."
      }
    },
    {
      "id": "190260528",
      "topics": ["Resumen", "LLM", "UX"],
      "title": "Podcast Latent Space 1/6/23 [Resumen] - Construyendo el Scenius de IA × UX — con Linus Lee de Notion AI",
      "slug": "latent-space-podcast-6-1-23-summary-building-the-ai-x-ux-scenius-with-linus-le",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:00:12+01:00",
      "description": "Explora el enfoque transformador de Notion AI hacia la IA y UX. Profundiza en el futuro de los espacios de trabajo aumentados por IA, el valor mas alla de las interfaces de chat y perspectivas sobre el trabajo de conocimiento efectivo. Resumen del encuentro AI×UX NYC incluido!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 1/6/23 [Resumen] - Scenius de IA × UX",
        "description": "Explora el enfoque transformador de Notion AI hacia la IA y UX."
      }
    },
    {
      "id": "190260557",
      "topics": ["Resumen", "Codigo", "LLM", "Agentes"],
      "title": "Podcast Latent Space 25/5/23 [Resumen] - Depurando Internet con agentes de IA – con Itamar Friedman de Codium AI y AutoGPT",
      "slug": "latent-space-podcast-5-25-23-summary-debugging-the-internet-with-ai-agents-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:58:27+01:00",
      "description": "Explora el futuro de la IA con Itamar Friedman de Codium AI en 'Depurando Internet'. Profundiza en agentes 'DRY Extremo', la sincronizacion rapida de especificaciones y pruebas, y el equilibrio entre codigo y pruebas. Ademas, perspectivas de Toran y una mirada exclusiva a la hoja de ruta de AutoGPT!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 25/5/23 [Resumen] Depurando Internet",
        "description": "Profundiza en agentes 'DRY Extremo', la sincronizacion rapida de especificaciones y pruebas, y el equilibrio entre codigo y pruebas."
      }
    },
    {
      "id": "190260640",
      "topics": ["Resumen", "Codigo Abierto", "LLM"],
      "title": "Podcast Latent Space 5/5/23 [Resumen] - Sin Foso: La IA Cerrada recibe su llamada de despertar de Codigo Abierto — con Simon Willison",
      "slug": "latent-space-podcast-5-5-23-summary-no-moat-closed-ai-gets-its-open-source-wakeup",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:49:18+01:00",
      "description": "Explora 'Sin Foso: El Despertar del Codigo Abierto de la IA Cerrada' con Simon Willison. Profundiza en las perspectivas del memo filtrado del Foso de Google, la Fuga de Cerebros de Google y el impulso de velocidad de Python con Mojo.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 5/5/23 [Resumen] - Sin Foso",
        "description": "Explora 'Sin Foso: El Despertar del Codigo Abierto de la IA Cerrada' con Simon Willison. Profundiza en las perspectivas del memo filtrado del Foso de Google."
      }
    },
    {
      "id": "190260671",
      "topics": ["LLM", "Codigo", "Resumen"],
      "title": "Podcast Latent Space 3/5/23 [Resumen] - Entrenando un LLM de Codigo SOTA en 1 semana y Cuantificando las Vibraciones — con Reza Shabani de Replit",
      "slug": "latent-space-podcast-5-3-23-summary-training-a-sota-code-llm-in-1-week-and-quanti",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:46:08+01:00",
      "description": "Ep. 10 con Reza Shabani: Profundiza en el entrenamiento rapido de un LLM de Codigo de ultima generacion, explora el futuro de Replit Ghostwriter y viaja de Finanzas a IA. Descubre la transicion de Kaplan a Chinchilla y mas!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 3/5/23 [Resumen] - LLM de Codigo SOTA",
        "description": "Ep. 10 con Reza Shabani: Profundiza en el entrenamiento rapido de un LLM de Codigo de ultima generacion!"
      }
    },
    {
      "id": "190629271",
      "topics": ["LLM", "Modelos Pequenos", "Resumen"],
      "title": "Podcast Latent Space 28/4/23 [Resumen] - Mapeando el futuro de los Modelos *verdaderamente* Abiertos y Entrenando Dolly por $30 — con Mike Conover de Databricks",
      "slug": "latent-space-podcast-4-28-23-summary-mapping-the-future-of-truly-open-models-and",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:33:12+01:00",
      "description": "Explora el futuro de los modelos abiertos con Mike Conover de Databricks. Profundiza en la creacion de Dolly, su transicion de 1.0 a 2.0 y las influencias detras de su desarrollo. El Ep.9 toca la infraestructura de modelos, la vision de Databricks y mas. #IA #ModelosAbiertos #Dolly",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 28/4/23 [Resumen] - Mike de Databricks",
        "description": "El Ep.9 toca la infraestructura de modelos, la vision de Databricks y mas. #IA #ModelosAbiertos #Dolly"
      }
    },
    {
      "id": "191164291",
      "topics": ["LLM", "Empresa", "Resumen"],
      "title": "Podcast Latent Space 21/4/23 [Resumen] - Busqueda impulsada por IA para la Empresa — con Deedy Das de Glean",
      "slug": "latent-space-podcast-4-21-23-summary-ai-powered-search-for-the-enterprise-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:31:31+01:00",
      "description": "Ep.8: Sumérgete en la IA en busqueda empresarial con Deedy Das de Glean. Desempaqueta desafios en crear un gigante de busqueda IA, comparaciones Google vs ChatGPT, complejidades de infraestructura IA, deteccion de texto generado por IA y por que las empresas necesitan mas que solo QA de Documentos.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 21/4/23 [Resumen] - con Deedy Das",
        "description": "Ep.8: Sumérgete en la IA en busqueda empresarial con Deedy Das de Glean. Desempaqueta desafios en crear un gigante de busqueda IA, comparaciones Google vs ChatGPT ..."
      }
    },
    {
      "id": "191165673",
      "topics": ["Resumen", "Vision"],
      "title": "Podcast Latent Space 13/4/23 [Resumen] - Modelo de Segmentacion de Cualquier Cosa y los Problemas Dificiles de Vision por Computadora — con Joseph Nelson de Roboflow",
      "slug": "latent-space-podcast-4-13-23-summary-segment-anything-model-and-the-hard-problems",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:30:03+01:00",
      "description": "Explora el Ep.7 con Joseph Nelson sobre el Modelo de Segmentacion de Cualquier Cosa de Meta. Profundiza en el futuro de la Vision por Computadora, la importancia del OCR, Segmentacion de Imagenes y mas. #Roboflow #IA",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
      },
      "seo": {
        "title": "Podcast Latent Space 13/4/23 [Resumen] - Segmentacion de Cualquier Cosa",
        "description": "Profundiza en el futuro de la Vision por Computadora, la importancia del OCR, Segmentacion de Imagenes y mas. #Roboflow #IA"
      }
    }
  ],
  "blogContent": {
    "id": "190259216",
    "topics": ["Resumen", "Codigo Abierto"],
    "title": "Podcast de Espacio Latente 7/2/23 [Resumen] Tendencias de IA: un episodio cruzado de Espacio Latente x IA Practica",
    "slug": "latent-space-podcast-7-2-23-summary-ai-trends-a-latent-space-x-practical-ai-cross",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-05T09:08:36+01:00",
    "description": "Explora la fusion de IA Practica y Espacio Latente mientras profundizan en las principales tendencias de IA de 2023, reflexionan sobre episodios destacados y comparten ideas sobre como navegar la evolucion de la IA.",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Original Link: "
                    },
                    {
                      "url": "https://www.latent.space/p/practical-ai-trends#details",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "[Practical AI] AI Trends: a Latent Space x Practical AI crossover pod!"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Summary"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a crossover episode with the Latent Space podcast, host Daniel Whitenack from Practical FM joined co-hosts Alessio Fanelli and Shawn Wang. The discussion began with introductions, with Whitenack highlighting his background in computational physics, his tenure as a data scientist at SIL International, and his recent venture with Prediction Guard. The podcast touched on the rise of AI, its global community, and the practical implications and uses of AI technology in everyday life."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Daniel also shed light on episodes of Practical AI, sharing personal favorites and audience hits. Episodes like \"Fully Connected\" are particularly enlightening, as they delve deep into AI topics such as ChatGPT, diffusion models, and AlphaFold. Another highlight was the \"AI for Africa\" series, which emphasized the importance of AI being inclusive and accommodating for various global use cases."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Throughout the conversation, there was a consistent theme of focusing on the practical, day-to-day uses of AI, rather than getting caught up in the hype."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "screenshot-2023-08-15-at-5-20-38-pm",
            "height": 532,
            "width": 1600,
            "filename": "screenshot-2023-08-15-at-5-20-38-pm.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "AI Roundtable: Insights, Excitements, and Challenges in the Modern AI Landscape"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a podcast episode, Shawn Wang, Alessio Fanelli, and Daniel Whitenack discuss their personal episode highlights, trends in the AI industry, and the evolution of model evaluation."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Episode Highlights:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Alessio Fanelli's highlight was the episode with Mike Conover from Databricks discussing DALL-E. He emphasizes Mike's passion and the exciting release of the RedPajama dataset."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Shawn Wang recalled the news-driven episode on ChatGPT Plugins where 4,000 people tuned in. He finds value in capturing real-time reactions to significant AI developments."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Daniel Whitenack reminisces about the time when image generation was trending but now finds himself immersed in NLP and language models."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Trends in the AI Industry:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "The most popular episode was on Metaflow, a Python package for full-stack data science modeling, which resonated with listeners due to the challenges of the model lifecycle in practical applications."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Daniel notes that the industry is transitioning from traditional MLOps to a new kind of operations (possibly termed LLMOps), focused more on leveraging pre-trained models."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Alessio mentions that their most popular episodes revolved around model-based topics, including discussions about the limitations of traditional benchmarks and the need for better evaluations."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Model Evaluation:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Alessio talked about the rapid evolution of benchmarks, indicating the need for better evaluation metrics for models like GPT-4."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Shawn brings up HellaSwag's adversarially-generated benchmarks and the surprising revelation that less than 1% of the data for \"Segment Anything from Meta\" was human-generated."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Daniel observes the growing trend of model-generated output and datasets, emphasizing that the scale of simulated or augmented data is astounding."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Shawn voices concerns about \"mode collapse\" and the possibility of models over-optimizing for median use cases, potentially sidelining low-resource applications."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Daniel believes that linguistic diversity in large language models can benefit downstream, lower-resource languages."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Throughout the discussion, the trio touches upon the evolving landscape of AI, the importance of benchmarks, and the challenges and potential of using models to evaluate other models."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls6-img1",
            "height": 936,
            "width": 936,
            "filename": "abls6-img1.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692149396-abls6-img1.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Grassroots AI Efforts & The Changing Landscape of AI Models"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["emphasis"],
                      "value": "Shawn Wang"
                    },
                    {
                      "type": "span",
                      "value": " explores the impact and mission of "
                    },
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Masakhane"
                    },
                    {
                      "type": "span",
                      "value": ", a grassroots organization of African NLP researchers creating relevant technologies for Africa. "
                    },
                    {
                      "type": "span",
                      "marks": ["emphasis"],
                      "value": "Daniel Whitenack"
                    },
                    {
                      "type": "span",
                      "value": " elaborates on the unique challenges faced by African communities, stressing the importance of building AI solutions tailored to specific needs. He cites examples of advanced tech in the U.S., such as tractors running on Kubernetes clusters, versus the contrasting requirements in Africa, like drought identification or disaster relief."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Daniel further delves into the \"AI for Africa\" episodes, highlighting the vast difference in tech applications across regions. He encourages global participation, pointing to Masakhane as a model for how local expertise can shape meaningful technology."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Turning to the topic of AI models, Daniel references an insightful episode from "
                    },
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Raj Shah"
                    },
                    {
                      "type": "span",
                      "value": " of Hugging Face on the capabilities of Large Language Models (LLMs). The episode discusses various axes like model accessibility, commercial usability, task specificity, and more. This discussion provides a guide for navigating the overwhelming number of models available today."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Both Shawn and Daniel discuss their strategies for staying updated in the rapidly evolving AI landscape. They touch on the role of platforms like Twitter and Hugging Face, emphasizing the importance of keeping an eye on download statistics to gauge model popularity."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Finally, Daniel highlights an interesting collaboration where grassroots efforts led to the creation of language models in six African languages. These models, discovered by Meta on Hugging Face, have now been incorporated into new models released by the tech giant. This showcases the full-circle impact of community-driven AI initiatives, further emphasizing the significance of tailored technological solutions."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls6-img2",
            "height": 936,
            "width": 936,
            "filename": "abls6-img2.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692149410-abls6-img2.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "AI Landscape Evolution: From Open-Source Advocacy to the Rise of AI Engineering"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a podcast episode, Alessio Fanelli highlights the shift in the AI landscape, pointing to how a proliferation of models are becoming available on platforms like Hugging Face, democratizing access and creating opportunities for more players to participate. The conversation delves into Jonathan Frankle's advocacy for keeping AI models open-source. Shawn Wang and Daniel Whitenack discuss the potential of incorporating audio enhancements to podcasts to maintain engagement. They also discuss a past episode with Kirsten Lum, who addressed the challenges of managing ML tasks in mid-sized organizations compared to larger enterprises."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "A significant part of the conversation focuses on the practical implementation of AI in enterprises. Daniel underscores that while many companies experiment with tools like ChatGPT, they often don't progress past superficial usage. He emphasizes the need for businesses to dig deeper into the applications of these models, from prompt engineering to more complex operations. The discussion evolves into the topic of prompt engineering, its hype, and its genuine significance in the AI ecosystem. Shawn Wang introduces the term \"AI engineering,\" suggesting that the discipline is evolving as a subset of software engineering, marking a shift from traditional ML roles to a fusion with general software engineering roles."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls6-img3",
            "height": 936,
            "width": 936,
            "filename": "abls6-img3.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692149425-abls6-img3.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Transitioning to AI: Challenges, the Importance of UX, and the Evolution of Data Labeling"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Unique Challenges of Engineers vs. Data Scientists Transitioning to AI"
                    },
                    {
                      "type": "span",
                      "value": " Daniel Whitenack and Shawn Wang discuss the challenges faced by software engineers and data scientists as they transition into AI-focused roles. For software developers, confronting non-deterministic systems, particularly those they don't fully control, like blackbox models from OpenAI, presents a unique hurdle. They're also working with a model whose capabilities have not been fully tapped into yet."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "From a data scientist's perspective, Whitenack highlights the instinct to jump into model training and fine-tuning, even though significant achievements can be made through data augmentation and prompting. He underscores that data scientists have dealt with uncertainties for a while, but it's different when they aren't in charge of the datasets or the training."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "The Value of AI User Experience (UX)"
                    },
                    {
                      "type": "span",
                      "value": " Wang introduces the concept of AI UX, emphasizing that the final step of showcasing AI output in a user-friendly manner can be as crucial as training the model. This is evidenced by OpenAI's ChatGPT, which many deem a UX breakthrough. Whitenack concurs, suggesting that while innovations in modeling and data are critical, a poor user experience can nullify those advances. He cites Gmail's smooth AI-powered autocomplete feature as an example of seamless AI integration that provides immediate value to users."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "Discussion on Dataset Evolution and Curation"
                    },
                    {
                      "type": "span",
                      "value": " Whitenack mentions the evolution in NLP datasets and the popularity of open-source tools like Label Studio for data labeling. Wang notes that Label Studio has introduced tools for fine-tuning generative AI models. Whitenack discusses the challenges companies face in understanding instruction-tuned models and emphasizes the importance of clear tooling around this process to make it more approachable."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Finally, Wang ponders on why multiple data-labeling companies like Label Box and Label Studio continue to emerge and flourish even when giants like Scale already exist in the market, pointing to the ongoing importance and evolution of data-centric AI."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls6-img4",
            "height": 936,
            "width": 936,
            "filename": "abls6-img4.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692149436-abls6-img4.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Deciphering AI's Shift from Model-Centric to Data-Centric Paradigms"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "AI Customization and The Evolution of Data Use"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["emphasis"],
                      "value": "Daniel Whitenack"
                    },
                    {
                      "type": "span",
                      "value": " discusses the evolving relationship between AI and businesses, emphasizing a shift from a model-centric to a data-centric approach. Many enterprises, he notes, are now thinking about leveraging state-of-the-art models for their data. This involves either enhancing these models with their data or fine-tuning them, a perspective reflected by the rise of APIs that offer fine-tuning."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["emphasis"],
                      "value": "Shawn Wang"
                    },
                    {
                      "type": "span",
                      "value": " raises a pertinent point on OpenAI's shift away from fine-tuning for models like GPT-3.5 and GPT-4. He also delves into the gray area of unlabeled datasets for unsupervised and self-supervised learning. The conversation further delves into the challenges of determining the right data mix for training models and highlights the lack of clarity on the best practices."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Whitenack adds insight into the world of data mixes, suggesting that the exact composition of data used by top models like those from OpenAI remains unknown. This creates a challenge for those attempting to emulate such models. He emphasizes the importance of experimenting with different mixes of data to optimize model training. Whitenack encourages AI enthusiasts to remain hands-on, leveraging the array of available tools to gain a better understanding of models and to foster innovation."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a lightning round, Whitenack highlights his astonishment at the general-purpose capabilities of large language models, especially beyond traditional NLP tasks. He points out the huge potential for exploration in AI, especially with respect to languages other than English and Mandarin, and also in diverse modalities of communication like sign language. He ends with a call to action, urging individuals to get involved and hands-on with AI models to gain intuition and insight."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": ["strong"],
                      "value": "End Note"
                    },
                    {
                      "type": "span",
                      "value": ": The transcript is open source and available on GitHub for improvements."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls6-img5",
            "height": 936,
            "width": 936,
            "filename": "abls6-img5.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692149458-abls6-img5.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Principales tendencias de IA de 2023, reflexion sobre episodios destacados e ideas sobre como navegar la evolucion de la IA.",
      "title": "Podcast de Espacio Latente 7/2/23 [Resumen] Tendencias de IA",
      "twitterCard": null,
      "image": {
        "width": 1600,
        "height": 532,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
      }
    }
  },
  "topics": ["Resumen", "Codigo Abierto"]
}
