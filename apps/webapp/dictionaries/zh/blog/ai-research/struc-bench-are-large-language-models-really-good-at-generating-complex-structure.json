{
  "relatedBlogs": [
    {
      "id": "198277124",
      "topics": ["大型语言模型", "金融", "医疗", "法律", "提示工程"],
      "title": "通过阅读理解适应大型语言模型",
      "slug": "adapting-large-language-models-via-reading-comprehension",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:22+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "通过阅读理解适应大型语言模型",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277342",
      "topics": ["大型语言模型", "多语言"],
      "title": "OpenBA:一个从头预训练的开源150亿参数双语非对称seq2seq模型",
      "slug": "openba-an-open-sourced-15b-bilingual-asymmetric-seq2seq-model-pre-trained-from-sc",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:02+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "OpenBA:一个从头预训练的开源150亿参数双语...模型...",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277117",
      "topics": ["大型语言模型", "检索"],
      "title": "PDFTriage:针对长结构化文档的问答系统",
      "slug": "pdftriage-question-answering-over-long-structured-documents",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:49+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "PDFTriage:针对长结构化文档的问答系统",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277138",
      "topics": ["大型语言模型", "微调"],
      "title": "Sorted LLaMA:通过排序微调(SoFT)释放大型语言模型中间层的动态推理潜力",
      "slug": "sorted-llama-unlocking-the-potential-of-intermediate-layers-of-large-language-mod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:31+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Sorted LLaMA:...使用排序微调(SoFT)进行动态推理",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277150",
      "topics": ["大型语言模型", "指令调优", "多模态"],
      "title": "指令调优大型多模态模型扩展的实证研究",
      "slug": "an-empirical-study-of-scaling-instruct-tuned-large-multimodal-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:15+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "指令调优大型多模态模型扩展的实证研究",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277217",
      "topics": ["大型语言模型", "隐私", "边缘计算"],
      "title": "利用大型语言模型从隐私保护掩码中恢复",
      "slug": "recovering-from-privacy-preserving-masking-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:26+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "利用大型语言模型从隐私保护掩码中恢复",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277239",
      "topics": ["大型语言模型", "聊天"],
      "title": "S3-DST:大型语言模型时代的结构化开放域对话分割和状态跟踪",
      "slug": "s3-dst-structured-open-domain-dialogue-segmentation-and-state-tracking-in-the-era",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:11+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "S3-DST:结构化开放域对话分割和状态跟踪...",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277253",
      "topics": ["大型语言模型", "音频"],
      "title": "利用大型语言模型增强口语理解的文本",
      "slug": "augmenting-text-for-spoken-language-understanding-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:49+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "利用大型语言模型增强口语理解的文本...",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277277",
      "topics": ["大型语言模型", "压缩"],
      "title": "语言建模即压缩",
      "slug": "language-modeling-is-compression",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:32+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "语言建模即压缩",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277345",
      "topics": ["大型语言模型", "多语言"],
      "title": "百川2:开放大规模语言模型",
      "slug": "baichuan-2-open-large-scale-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:59:10+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "百川2:开放大规模语言模型",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277446",
      "topics": ["大型语言模型", "幻觉"],
      "title": "验证链减少大型语言模型的幻觉",
      "slug": "chain-of-verification-reduces-hallucination-in-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:21:05+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "验证链减少大型语言模型的幻觉",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277458",
      "topics": ["大型语言模型", "幻觉", "实体", "结构化数据"],
      "title": "LMDX:基于语言模型的文档信息提取和定位",
      "slug": "lmdx-language-model-based-document-information-extraction-and-localization",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:20:31+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "LMDX:..文档信息提取和定位",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277209",
      "topics": ["大型语言模型", "数据"],
      "title": "SlimPajama-DC:理解大型语言模型训练的数据组合",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T23:43:32+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "SlimPajama-DC:理解大型语言模型训练的数据组合",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277109",
      "topics": ["大型语言模型", "推理"],
      "title": "对比解码提高大型语言模型的推理能力",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T22:18:11+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "对比解码提高大型语言模型的推理能力",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198277099",
      "topics": ["大型语言模型", "多语言", "数据"],
      "title": "CulturaX:一个清洁、庞大、多语言的167种语言大型语言模型数据集",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T22:14:53+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "CulturaX:一个清洁、庞大、多语言的数据集...",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198044929",
      "topics": ["大型语言模型", "数据", "智能体"],
      "title": "推理型具身智能体的数据源",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:33:25+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "推理型具身智能体的数据源",
        "description": "摘要评论和评分\n"
      }
    },
    {
      "id": "198044900",
      "topics": ["大型语言模型", "实体", "微调"],
      "title": "利用上下文信息进行有效的实体显著性检测",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:30:50+01:00",
      "description": "摘要评论和评分",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "利用上下文信息...实体显著性检测",
        "description": "摘要评论和评分\n"
      }
    }
  ],
  "blogContent": {
    "id": "198277196",
    "topics": ["大型语言模型", "结构化数据"],
    "title": "Struc-Bench: 大型语言模型真的擅长生成复杂结构化数据吗?",
    "slug": "struc-bench-are-large-language-models-really-good-at-generating-complex-structure",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2024-05-25T03:38:38+01:00",
    "description": "摘要评论和评分",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Published on Sep 16·Featured in "
                    },
                    {
                      "url": "https://huggingface.co/papers?date=2023-09-19",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Daily Papers"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": " on Sep 18Authors:Xiangru Tang,Yiming Zong,"
                    },
                    {
                      "url": "https://huggingface.co/yilunzhao",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Yilun Zhao"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/armanc",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Arman Cohan"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",Mark Gerstein"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Abstract"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Despite the power of Large Language Models (LLMs) like GPT-4, they still struggle with tasks that require generating complex, structured outputs. In this study, we assess the capability of Current LLMs in generating complex structured data and propose a structure-aware fine-tuning approach as a solution to improve this ability. To perform a comprehensive evaluation, we propose Struc-Bench, include five representative LLMs (i.e., GPT-NeoX 20B, GPT-3.5, GPT-4, and Vicuna) and evaluate them on our carefully constructed datasets spanning raw text, HTML, and LaTeX tables. Based on our analysis of current model performance, we identify specific common formatting errors and areas of potential improvement. To address complex formatting requirements, we utilize FormatCoT (Chain-of-Thought) to generate format instructions from target outputs. Our experiments show that our structure-aware fine-tuning method, when applied to LLaMA-7B, significantly improves adherence to natural language constraints, outperforming other evaluated LLMs. Based on these results, we present an ability map of model capabilities from six dimensions (i.e., coverage, formatting, reasoning, comprehension, pragmatics, and hallucination). This map highlights the weaknesses of LLMs in handling complex structured outputs and suggests promising directions for future work. Our code and models can be found at https://github.com/gersteinlab/Struc-Bench."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.08963",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "View arXiv page"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.08963",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "View PDF"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Commentary"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The paper \"Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?\" targets a significant challenge in the domain of Large Language Models (LLMs) — generating complex structured outputs."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Key Takeaways:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Problem Identification"
                            },
                            {
                              "type": "span",
                              "value": ": Despite the prowess of modern LLMs, their ability to generate structured outputs like tables, HTML, or LaTeX, remains challenging."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Struc-Bench Benchmark"
                            },
                            {
                              "type": "span",
                              "value": ": This work introduces a comprehensive benchmark to assess the capability of LLMs in generating structured data, evaluating several state-of-the-art models across various structured formats."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Detailed Analysis"
                            },
                            {
                              "type": "span",
                              "value": ": The researchers identify common formatting errors in LLM outputs, providing insights into the weaknesses of these models when tasked with generating structured content."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Structure-Aware Fine-tuning"
                            },
                            {
                              "type": "span",
                              "value": ": A novel method, FormatCoT, is introduced to generate format instructions from target outputs, improving the model's adherence to complex structural requirements."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Ability Map"
                            },
                            {
                              "type": "span",
                              "value": ": The authors present a map detailing model capabilities across six dimensions, highlighting areas of strengths and weaknesses."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Potential Real-World Impact:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Complex Output Generation"
                            },
                            {
                              "type": "span",
                              "value": ": The findings and proposed solutions can advance LLMs' abilities to generate complex structured outputs, vital for tasks like document generation, website design, and data table creation."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Better Model Evaluations"
                            },
                            {
                              "type": "span",
                              "value": ": Struc-Bench can become a standard benchmark for future models, ensuring they're tested for their capabilities in structured output generation."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Structured Data in Applications"
                            },
                            {
                              "type": "span",
                              "value": ": Improved capabilities in structured data generation can enhance applications like automatic report writing, code generation, or content management systems."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Guidance for Future Research"
                            },
                            {
                              "type": "span",
                              "value": ": The identification of common errors and the ability map will guide researchers on where to focus their efforts."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Challenges:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Complexity"
                            },
                            {
                              "type": "span",
                              "value": ": While the proposed methods show promise, there's inherent complexity in generating structured content, and perfecting this will remain a challenge."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": ["strong"],
                              "value": "Adoption"
                            },
                            {
                              "type": "span",
                              "value": ": The broader impact would depend on how the community adopts the benchmark and the structure-aware fine-tuning method in their research and applications."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Considering the critical nature of generating structured data and the potential implications of improving this ability in LLMs:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "I'd rate the real-world impact of this paper as a 9 out of 10."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The introduction of a structured data benchmark, insights into model errors, and a novel fine-tuning approach have the potential to push the boundaries of what LLMs can achieve in real-world structured data generation tasks."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "摘要评论和评分",
      "title": "Struc-Bench:..生成复杂结构化数据?",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": ["大型语言模型", "结构化数据"]
}
